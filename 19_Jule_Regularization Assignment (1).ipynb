{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f72419e-9fc0-4ce3-9a42-d010dbd5d6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. What is regularization in the context of deep learning  Why is it important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18dda443-18c1-4719-bef3-3abfd83a974d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans = Regularization is a set of techniques that can prevent overfitting in\n",
    "neural networks and thus improve the accuracy of a Deep Learning model when \n",
    "facing completely new data from the problem domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb8d6dd-46c7-43d9-831a-77137d8820d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a3ff10-ac0f-49f9-8c0b-b032de257ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "2.Explain the bias-variance tradeoff and how regularization helps in addressing this tradeoff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b46933-02f6-47c0-80a4-1f92e58799cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans = Regularization will help select a midpoint between the first scenario of\n",
    "high bias and the later scenario of high variance.\n",
    "This ideal goal of generalization in terms of bias and variance is \n",
    "a low bias and a low variance which is near impossible or difficult to achieve.\n",
    "Hence, the need of the trade-off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9749aefb-faf5-47f4-adfa-350aaaf310b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe34dc3-851b-4b70-82ab-287ceb772ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "3.Describe the concept of L1 and 2 regularization.How do they differ in terms of penalty calculation and\n",
    "their effects on the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baeae536-10eb-499a-8de3-36eadf4f25c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans = L1 Regularization, also called a lasso regression,\n",
    "adds the “absolute value of magnitude” of the coefficient as a penalty term to the loss function.\n",
    "L2 Regularization, also called a ridge regression, adds the “squared magnitude” of the coefficient \n",
    "as the penalty term to the loss function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d45f9a4-0df6-4bd0-b0fa-0b96e09d1d58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a181a805-5a42-45fa-ae29-42b27405630f",
   "metadata": {},
   "outputs": [],
   "source": [
    "4.Discuss the role of regularization in preventing overfitting and improving the generalization of deep\n",
    "learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ca09d4-c188-4918-a70f-8a45528d4fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans = 1.Early stopping. Early stopping pauses the training phase before the machine learning model learns the noise in the data. \n",
    "2.Pruning.  might identify several features or parameters that impact the final prediction when you build a model. \n",
    "3.Regularization. \n",
    "4.Ensembling. \n",
    "5.Data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee9ed32-c186-4646-b4b1-fb8e2c61134f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f333d17a-fe8e-4a8c-8422-aeba87182ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "5.Explain Dropout regularization and how it works to reduce overfitting. Discuss the impact of Dropout on\n",
    "model training and inference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac0037e-cfdd-4aa9-b2ba-d68e1f7e1f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans = Dropout regularization will ensure the following: \n",
    "    The neurons can not  rely on one input because it might be dropped out at random.\n",
    "    This reduces bias due to over-relying on one input, bias is a major cause of overfitting.\n",
    "    Neurons will not learn redundant details of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4727fdfb-7cbd-44c6-a04d-428c3c81f26f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31a07f5-de2e-4464-a478-36ea2aad6fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "6.Describe the concept of Early ztopping as a form of regularization. How does it help prevent overfitting\n",
    "during the training process?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171fd1fa-b390-4ca2-9a80-2affffdbc9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans = In deep machine learning, \n",
    "early stopping is a form of regularization used to avoid overfitting \n",
    "when training a learner with an iterative method, such as gradient descent.\n",
    "Such methods update the learner so as to make it better fit the training data with each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3217caf8-11ae-4efd-807e-03e7e26bc7b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd52ac4-a36e-49ff-a722-c324daa7b68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "7.Explain the concept of Batch Normalization and its role as a form of regularization. How does Batch\n",
    "Normalization help in preventing overfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e07db4-59e5-4408-8693-4f4ea8f903bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ans = Reduces overfitting. Batch normalisation has a regularising effect since\n",
    "it adds noise to the inputs of every layer. \n",
    "This discourages overfitting since the model no longer produces \n",
    "deterministic values for a given training example alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1068ff88-5871-44c1-8ce4-528103f76cfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef53ccc-90aa-4885-a01f-3a97b93b17a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65132973-19e4-4c60-bf16-a4d81a360c42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
